webbscraper
===========
<h3>Vad tror Du vi har för skäl till att spara det skrapade datat i JSON-format?<h3/>
<p>Att det sparas i ett universelt format som många använder och förstår. JSON ger ett bra överskådligt sätt att se och läsa informatin för personer
samtidigt som det ger en bra objectorieterad uppdelning av datat.
<p/>

<h3>Olika jämförelsesiter är flitiga användare av webbskrapor. Kan du komma på fler typer av tillämplingar där webbskrapor förekommer?<h3/>
<p>Sammanställa infomration för att olika ändamål. t.ex. ta fram personinformation från en typ av sidor för att kontakta/ge reklam till dessa. Man kan sammanställa "färsk" data som behöver vara up-to-date med ett enda klick.
Också för att göra olika typer av analyser av webben eller olika sidor på den.
<p/>

<h3>Hur har du i din skrapning underlättat för serverägaren?<h3/>
<p>Jag identifierar varje anrop och ser att att den endast håller sig uppdaterad var 5e minut, ifall det inte önskas att göra en uppdatering just nu.
<p/>

<h3>Vilka etiska aspekter bör man fundera kring vid webbskrapning?<h3/>
<p>Man bör fråga om lov innan man skrapar då det kan påverka server. Man bör också vara noga med att ge källförteckning till den datan man skrapar.
Det ligger ungefär under samma etiska aspekter som i verkligen, man kan inte ta någon annans bok och ge ut som sin egen.
<p/> 

<h3>Vad finns det för risker med applikationer som innefattar automatisk skrapning av webbsidor? Nämn minst ett par stycken!<h3/>
<p>Det måste underhållas, ifall minsta ändring sker på någon av sidorna som skrapas så måste detta korrigeras vid skrapning. Om man många använder applikationen sätter det stor press på sidorna som skrapas. 
<p/>

<h3>Tänk dig att du skulle skrapa en sida gjord i ASP.NET WebForms. Vad för extra problem skulle man kunna få då?<h3/>
<p>Varje anrop kräver att man skickar med extra information för att behålla AP.NET-aplpikationens "state"
<p/>

<h3>Välj ut två punkter kring din kod du tycker är värd att diskutera vid redovisningen. Det kan röra val du gjort, tekniska lösningar eller lösningar du inte är riktigt nöjd med.<h3/>
<p>Nu görs allting via en indexsida. finns det någon speciellt bestpractice eller sätt att bygga en skrapa på?
<p/>

<h3>Hitta ett rättsfall som handlar om webbskrapning. Redogör kort för detta.<h3/>
<h4>  Craiglist vs 3Taps Case - "http://en.wikipedia.org/wiki/Craigslist_v._3Taps"<h4/>
<p> Bla. företaget 3Taps skrapade information från Craiglist för att skapa ett alternativt interface för användare.
Detta ville inte Craiglist som försökte blockera deras IP:n, detta fungerade dock inte. 
Till slut så bestämde sig Craiglists för att stämma företagen.<p/>
  
 <p> "The court held that sending a cease and desist letter and blocking a client's IP address are sufficient to   qualify   as notice under the Computer Fraud and Abuse Act. 3Taps should have known that Craigslist was revoking its authorization to access the site.[1] The motion to dismiss was granted in part, and denied in part. As of March 19, 2014 this case has not yet been decided."
<p/>


<h3>Känner du att du lärt dig något av denna uppgift?<h3/>
<p>Uppgiften var intressant och bra i att lära ut grunderna för webskrapning.
<p/>
